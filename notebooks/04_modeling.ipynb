{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ü§ñ NeoScore - Credit Scoring Models\n",
                "\n",
                "**Autor**: Luca Camus  \n",
                "**Fecha**: Enero 2026  \n",
                "**Objetivo**: Entrenar modelos de ML para predecir riesgo crediticio\n",
                "\n",
                "**Modelos a implementar**:\n",
                "1. Logistic Regression (baseline interpretable)\n",
                "2. Random Forest (ensemble robusto)\n",
                "3. XGBoost (estado del arte)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Configuraci√≥n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Instalar dependencias\n",
                "!pip install google-cloud-bigquery pandas matplotlib seaborn scikit-learn xgboost imbalanced-learn --quiet"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Imports\n",
                "from google.colab import auth\n",
                "auth.authenticate_user()\n",
                "\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from google.cloud import bigquery\n",
                "\n",
                "# Scikit-learn\n",
                "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.metrics import (\n",
                "    roc_auc_score, roc_curve, confusion_matrix, \n",
                "    classification_report, precision_recall_curve,\n",
                "    f1_score, accuracy_score\n",
                ")\n",
                "\n",
                "# XGBoost\n",
                "from xgboost import XGBClassifier\n",
                "\n",
                "# Imbalanced-learn (si hay desbalanceo)\n",
                "from imblearn.over_sampling import SMOTE\n",
                "\n",
                "# Configuraci√≥n\n",
                "plt.style.use('seaborn-v0_8-whitegrid')\n",
                "plt.rcParams['figure.figsize'] = (12, 6)\n",
                "np.random.seed(42)\n",
                "\n",
                "print('‚úÖ Configuraci√≥n completa')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Cargar Datos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cliente BigQuery\n",
                "PROJECT_ID = 'scoring-bancario'\n",
                "client = bigquery.Client(project=PROJECT_ID)\n",
                "\n",
                "# Cargar datos\n",
                "query = \"\"\"\n",
                "SELECT *\n",
                "FROM `scoring-bancario.analisis_bancario.customer_features`\n",
                "\"\"\"\n",
                "\n",
                "df = client.query(query).to_dataframe()\n",
                "print(f'üìä Dataset cargado: {df.shape[0]:,} clientes x {df.shape[1]} features')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Preparaci√≥n de Features (¬°Evitando Leakage!)\n",
                "\n",
                "‚ö†Ô∏è **IMPORTANTE**: NO usar `preliminary_credit_score` como feature"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Features PERMITIDAS (datos crudos, sin leakage)\n",
                "FEATURES = [\n",
                "    'age',                      # Demograf√≠a\n",
                "    'avg_balance',              # Balance\n",
                "    'last_balance',\n",
                "    'min_balance',\n",
                "    'max_balance',\n",
                "    'total_spend',              # Gasto\n",
                "    'avg_spend',\n",
                "    'max_spend',\n",
                "    'min_spend',\n",
                "    'std_spend',\n",
                "    'total_transactions',       # Actividad\n",
                "    'days_active',\n",
                "    'unique_transaction_days',\n",
                "    'transaction_frequency',\n",
                "    'spend_to_balance_ratio',   # Ratios\n",
                "    'spend_volatility',\n",
                "    'avg_daily_transactions',\n",
                "    'avg_daily_spend',\n",
                "]\n",
                "\n",
                "# Variable objetivo\n",
                "TARGET = 'high_risk_flag'\n",
                "\n",
                "print(f'üìä Features a usar: {len(FEATURES)}')\n",
                "print(f'üéØ Variable objetivo: {TARGET}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Verificar features disponibles\n",
                "available_features = [f for f in FEATURES if f in df.columns]\n",
                "missing_features = [f for f in FEATURES if f not in df.columns]\n",
                "\n",
                "print(f'‚úÖ Features disponibles: {len(available_features)}')\n",
                "if missing_features:\n",
                "    print(f'‚ö†Ô∏è Features no encontradas: {missing_features}')\n",
                "\n",
                "FEATURES = available_features"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Crear X e y\n",
                "X = df[FEATURES].copy()\n",
                "y = df[TARGET].copy()\n",
                "\n",
                "print(f'X shape: {X.shape}')\n",
                "print(f'y shape: {y.shape}')\n",
                "print(f'\\nüìä Distribuci√≥n del target:')\n",
                "print(y.value_counts(normalize=True).round(4) * 100)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Manejar valores nulos\n",
                "print('\\nüìä Nulos por columna antes de imputar:')\n",
                "null_counts = X.isnull().sum()\n",
                "print(null_counts[null_counts > 0])\n",
                "\n",
                "# Imputar nulos con la mediana\n",
                "X = X.fillna(X.median())\n",
                "\n",
                "print('\\n‚úÖ Nulos despu√©s de imputar:', X.isnull().sum().sum())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Divisi√≥n Train/Test"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Divisi√≥n estratificada (mantiene proporci√≥n de clases)\n",
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    X, y, \n",
                "    test_size=0.2, \n",
                "    random_state=42, \n",
                "    stratify=y\n",
                ")\n",
                "\n",
                "print(f'üìä Train: {X_train.shape[0]:,} samples ({X_train.shape[0]/len(X)*100:.0f}%)')\n",
                "print(f'üìä Test:  {X_test.shape[0]:,} samples ({X_test.shape[0]/len(X)*100:.0f}%)')\n",
                "\n",
                "print(f'\\nüìä Distribuci√≥n en Train:')\n",
                "print(y_train.value_counts(normalize=True).round(4) * 100)\n",
                "\n",
                "print(f'\\nüìä Distribuci√≥n en Test:')\n",
                "print(y_test.value_counts(normalize=True).round(4) * 100)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Escalar features para Logistic Regression\n",
                "scaler = StandardScaler()\n",
                "X_train_scaled = scaler.fit_transform(X_train)\n",
                "X_test_scaled = scaler.transform(X_test)\n",
                "\n",
                "print('‚úÖ Features escaladas')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Modelo 1: Logistic Regression (Baseline)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Entrenar Logistic Regression\n",
                "lr_model = LogisticRegression(\n",
                "    max_iter=1000,\n",
                "    random_state=42,\n",
                "    class_weight='balanced'  # Maneja desbalanceo\n",
                ")\n",
                "\n",
                "lr_model.fit(X_train_scaled, y_train)\n",
                "\n",
                "# Predicciones\n",
                "y_pred_lr = lr_model.predict(X_test_scaled)\n",
                "y_prob_lr = lr_model.predict_proba(X_test_scaled)[:, 1]\n",
                "\n",
                "# M√©tricas\n",
                "lr_auc = roc_auc_score(y_test, y_prob_lr)\n",
                "lr_gini = 2 * lr_auc - 1\n",
                "\n",
                "print('=' * 50)\n",
                "print('üìä LOGISTIC REGRESSION - Resultados')\n",
                "print('=' * 50)\n",
                "print(f'ROC-AUC: {lr_auc:.4f}')\n",
                "print(f'Gini:    {lr_gini:.4f}')\n",
                "print(f'\\n{classification_report(y_test, y_pred_lr, target_names=[\"Low Risk\", \"High Risk\"])}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Coeficientes (interpretabilidad)\n",
                "coef_df = pd.DataFrame({\n",
                "    'Feature': FEATURES,\n",
                "    'Coeficiente': lr_model.coef_[0]\n",
                "}).sort_values('Coeficiente', key=abs, ascending=False)\n",
                "\n",
                "print('üìä Features m√°s importantes (Logistic Regression):')\n",
                "print(coef_df.head(10).to_string(index=False))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Modelo 2: Random Forest"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Entrenar Random Forest\n",
                "rf_model = RandomForestClassifier(\n",
                "    n_estimators=100,\n",
                "    max_depth=10,\n",
                "    min_samples_split=10,\n",
                "    random_state=42,\n",
                "    class_weight='balanced',\n",
                "    n_jobs=-1\n",
                ")\n",
                "\n",
                "rf_model.fit(X_train, y_train)  # No necesita escalado\n",
                "\n",
                "# Predicciones\n",
                "y_pred_rf = rf_model.predict(X_test)\n",
                "y_prob_rf = rf_model.predict_proba(X_test)[:, 1]\n",
                "\n",
                "# M√©tricas\n",
                "rf_auc = roc_auc_score(y_test, y_prob_rf)\n",
                "rf_gini = 2 * rf_auc - 1\n",
                "\n",
                "print('=' * 50)\n",
                "print('üìä RANDOM FOREST - Resultados')\n",
                "print('=' * 50)\n",
                "print(f'ROC-AUC: {rf_auc:.4f}')\n",
                "print(f'Gini:    {rf_gini:.4f}')\n",
                "print(f'\\n{classification_report(y_test, y_pred_rf, target_names=[\"Low Risk\", \"High Risk\"])}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Feature Importance\n",
                "importance_df = pd.DataFrame({\n",
                "    'Feature': FEATURES,\n",
                "    'Importance': rf_model.feature_importances_\n",
                "}).sort_values('Importance', ascending=False)\n",
                "\n",
                "# Visualizar\n",
                "plt.figure(figsize=(10, 8))\n",
                "plt.barh(importance_df['Feature'][::-1], importance_df['Importance'][::-1], color='steelblue')\n",
                "plt.xlabel('Importancia')\n",
                "plt.title('Feature Importance - Random Forest', fontsize=14, fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print('\\nüìä Top 10 Features (Random Forest):')\n",
                "print(importance_df.head(10).to_string(index=False))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Modelo 3: XGBoost"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calcular scale_pos_weight para manejar desbalanceo\n",
                "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
                "print(f'Scale pos weight: {scale_pos_weight:.2f}')\n",
                "\n",
                "# Entrenar XGBoost\n",
                "xgb_model = XGBClassifier(\n",
                "    n_estimators=100,\n",
                "    max_depth=6,\n",
                "    learning_rate=0.1,\n",
                "    scale_pos_weight=scale_pos_weight,\n",
                "    random_state=42,\n",
                "    eval_metric='auc',\n",
                "    use_label_encoder=False\n",
                ")\n",
                "\n",
                "xgb_model.fit(X_train, y_train)\n",
                "\n",
                "# Predicciones\n",
                "y_pred_xgb = xgb_model.predict(X_test)\n",
                "y_prob_xgb = xgb_model.predict_proba(X_test)[:, 1]\n",
                "\n",
                "# M√©tricas\n",
                "xgb_auc = roc_auc_score(y_test, y_prob_xgb)\n",
                "xgb_gini = 2 * xgb_auc - 1\n",
                "\n",
                "print('=' * 50)\n",
                "print('üìä XGBOOST - Resultados')\n",
                "print('=' * 50)\n",
                "print(f'ROC-AUC: {xgb_auc:.4f}')\n",
                "print(f'Gini:    {xgb_gini:.4f}')\n",
                "print(f'\\n{classification_report(y_test, y_pred_xgb, target_names=[\"Low Risk\", \"High Risk\"])}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Comparaci√≥n de Modelos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Resumen de m√©tricas\n",
                "results = pd.DataFrame({\n",
                "    'Modelo': ['Logistic Regression', 'Random Forest', 'XGBoost'],\n",
                "    'ROC-AUC': [lr_auc, rf_auc, xgb_auc],\n",
                "    'Gini': [lr_gini, rf_gini, xgb_gini]\n",
                "}).sort_values('ROC-AUC', ascending=False)\n",
                "\n",
                "print('=' * 50)\n",
                "print('üìä COMPARACI√ìN DE MODELOS')\n",
                "print('=' * 50)\n",
                "print(results.to_string(index=False))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Curvas ROC\n",
                "fig, ax = plt.subplots(figsize=(10, 8))\n",
                "\n",
                "# Logistic Regression\n",
                "fpr_lr, tpr_lr, _ = roc_curve(y_test, y_prob_lr)\n",
                "ax.plot(fpr_lr, tpr_lr, label=f'Logistic Regression (AUC={lr_auc:.4f})', linewidth=2)\n",
                "\n",
                "# Random Forest\n",
                "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_prob_rf)\n",
                "ax.plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC={rf_auc:.4f})', linewidth=2)\n",
                "\n",
                "# XGBoost\n",
                "fpr_xgb, tpr_xgb, _ = roc_curve(y_test, y_prob_xgb)\n",
                "ax.plot(fpr_xgb, tpr_xgb, label=f'XGBoost (AUC={xgb_auc:.4f})', linewidth=2)\n",
                "\n",
                "# Diagonal\n",
                "ax.plot([0, 1], [0, 1], 'k--', label='Random (AUC=0.5)')\n",
                "\n",
                "ax.set_xlabel('False Positive Rate', fontsize=12)\n",
                "ax.set_ylabel('True Positive Rate', fontsize=12)\n",
                "ax.set_title('Curvas ROC - Comparaci√≥n de Modelos', fontsize=14, fontweight='bold')\n",
                "ax.legend(loc='lower right', fontsize=11)\n",
                "ax.grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. C√°lculo de KS Statistic"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def calculate_ks(y_true, y_prob):\n",
                "    \"\"\"Calcula KS Statistic\"\"\"\n",
                "    fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
                "    ks = max(tpr - fpr)\n",
                "    return ks\n",
                "\n",
                "# KS para cada modelo\n",
                "ks_lr = calculate_ks(y_test, y_prob_lr)\n",
                "ks_rf = calculate_ks(y_test, y_prob_rf)\n",
                "ks_xgb = calculate_ks(y_test, y_prob_xgb)\n",
                "\n",
                "print('=' * 50)\n",
                "print('üìä KS STATISTIC')\n",
                "print('=' * 50)\n",
                "print(f'Logistic Regression: KS = {ks_lr:.4f}')\n",
                "print(f'Random Forest:       KS = {ks_rf:.4f}')\n",
                "print(f'XGBoost:             KS = {ks_xgb:.4f}')\n",
                "print('\\nInterpretaci√≥n: KS > 0.40 es excelente, > 0.30 es bueno')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Tabla Final de Resultados"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Tabla final\n",
                "final_results = pd.DataFrame({\n",
                "    'Modelo': ['Logistic Regression', 'Random Forest', 'XGBoost'],\n",
                "    'ROC-AUC': [lr_auc, rf_auc, xgb_auc],\n",
                "    'Gini': [lr_gini, rf_gini, xgb_gini],\n",
                "    'KS': [ks_lr, ks_rf, ks_xgb]\n",
                "}).round(4)\n",
                "\n",
                "# Agregar ranking\n",
                "final_results['Ranking'] = final_results['ROC-AUC'].rank(ascending=False).astype(int)\n",
                "final_results = final_results.sort_values('Ranking')\n",
                "\n",
                "print('=' * 60)\n",
                "print('üìä RESULTADOS FINALES - NeoScore Credit Scoring')\n",
                "print('=' * 60)\n",
                "print(final_results.to_string(index=False))\n",
                "print('=' * 60)\n",
                "\n",
                "# Mejor modelo\n",
                "best_model = final_results.iloc[0]['Modelo']\n",
                "best_auc = final_results.iloc[0]['ROC-AUC']\n",
                "print(f'\\nüèÜ MEJOR MODELO: {best_model} (AUC={best_auc:.4f})')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualizaci√≥n final\n",
                "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
                "\n",
                "models = ['Logistic\\nRegression', 'Random\\nForest', 'XGBoost']\n",
                "colors = ['#3498db', '#2ecc71', '#e74c3c']\n",
                "\n",
                "# ROC-AUC\n",
                "axes[0].bar(models, [lr_auc, rf_auc, xgb_auc], color=colors)\n",
                "axes[0].set_title('ROC-AUC', fontsize=14, fontweight='bold')\n",
                "axes[0].set_ylim(0, 1)\n",
                "axes[0].axhline(0.5, color='gray', linestyle='--', alpha=0.5)\n",
                "for i, v in enumerate([lr_auc, rf_auc, xgb_auc]):\n",
                "    axes[0].text(i, v + 0.02, f'{v:.4f}', ha='center', fontweight='bold')\n",
                "\n",
                "# Gini\n",
                "axes[1].bar(models, [lr_gini, rf_gini, xgb_gini], color=colors)\n",
                "axes[1].set_title('Gini', fontsize=14, fontweight='bold')\n",
                "axes[1].set_ylim(0, 1)\n",
                "for i, v in enumerate([lr_gini, rf_gini, xgb_gini]):\n",
                "    axes[1].text(i, v + 0.02, f'{v:.4f}', ha='center', fontweight='bold')\n",
                "\n",
                "# KS\n",
                "axes[2].bar(models, [ks_lr, ks_rf, ks_xgb], color=colors)\n",
                "axes[2].set_title('KS Statistic', fontsize=14, fontweight='bold')\n",
                "axes[2].set_ylim(0, 1)\n",
                "axes[2].axhline(0.40, color='green', linestyle='--', alpha=0.5, label='Excelente (0.40)')\n",
                "axes[2].axhline(0.30, color='orange', linestyle='--', alpha=0.5, label='Bueno (0.30)')\n",
                "for i, v in enumerate([ks_lr, ks_rf, ks_xgb]):\n",
                "    axes[2].text(i, v + 0.02, f'{v:.4f}', ha='center', fontweight='bold')\n",
                "axes[2].legend(loc='upper right')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 11. Conclusiones"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print('=' * 60)\n",
                "print('üìä CONCLUSIONES - NeoScore Credit Scoring')\n",
                "print('=' * 60)\n",
                "\n",
                "print(f'''\n",
                "1. MEJOR MODELO: {best_model}\n",
                "   - ROC-AUC: {final_results.iloc[0][\"ROC-AUC\"]:.4f}\n",
                "   - Gini: {final_results.iloc[0][\"Gini\"]:.4f}\n",
                "   - KS: {final_results.iloc[0][\"KS\"]:.4f}\n",
                "\n",
                "2. FEATURES M√ÅS IMPORTANTES:\n",
                "''')\n",
                "print(importance_df.head(5).to_string(index=False))\n",
                "\n",
                "print(f'''\n",
                "3. INTERPRETACI√ìN:\n",
                "   - AUC > 0.70: Modelo aceptable para producci√≥n\n",
                "   - Gini > 0.40: Buena capacidad discriminativa\n",
                "   - KS > 0.30: Buena separaci√≥n entre clases\n",
                "\n",
                "4. PR√ìXIMOS PASOS:\n",
                "   - Optimizar hiperpar√°metros del mejor modelo\n",
                "   - Validar con cross-validation m√°s rigurosa\n",
                "   - Crear pipeline de producci√≥n\n",
                "   - Documentar modelo (Model Card)\n",
                "''')\n",
                "\n",
                "print('=' * 60)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}