{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ü§ñ NeoScore - Credit Scoring Models\n",
                "\n",
                "**Autor**: Luca Camus  \n",
                "**Fecha**: Enero 2026  \n",
                "**Objetivo**: Entrenar modelos de ML para predecir riesgo crediticio\n",
                "\n",
                "**Modelos a implementar**:\n",
                "1. Logistic Regression (baseline interpretable)\n",
                "2. Random Forest (ensemble robusto)\n",
                "3. XGBoost (estado del arte)\n",
                "4. **Random Forest - Solo Comportamiento** (sin variables de balance)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Configuraci√≥n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Instalar dependencias\n",
                "!pip install google-cloud-bigquery pandas matplotlib seaborn scikit-learn xgboost imbalanced-learn --quiet"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Imports\n",
                "from google.colab import auth\n",
                "auth.authenticate_user()\n",
                "\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from google.cloud import bigquery\n",
                "\n",
                "# Scikit-learn\n",
                "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.metrics import (\n",
                "    roc_auc_score, roc_curve, confusion_matrix, \n",
                "    classification_report, precision_recall_curve,\n",
                "    f1_score, accuracy_score\n",
                ")\n",
                "\n",
                "# XGBoost\n",
                "from xgboost import XGBClassifier\n",
                "\n",
                "# Imbalanced-learn (si hay desbalanceo)\n",
                "from imblearn.over_sampling import SMOTE\n",
                "\n",
                "# Configuraci√≥n\n",
                "plt.style.use('seaborn-v0_8-whitegrid')\n",
                "plt.rcParams['figure.figsize'] = (12, 6)\n",
                "np.random.seed(42)\n",
                "\n",
                "print('‚úÖ Configuraci√≥n completa')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Cargar Datos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cliente BigQuery\n",
                "PROJECT_ID = 'scoring-bancario'\n",
                "client = bigquery.Client(project=PROJECT_ID)\n",
                "\n",
                "# Cargar datos\n",
                "query = \"\"\"\n",
                "SELECT *\n",
                "FROM `scoring-bancario.analisis_bancario.customer_features`\n",
                "\"\"\"\n",
                "\n",
                "df = client.query(query).to_dataframe()\n",
                "print(f'üìä Dataset cargado: {df.shape[0]:,} clientes x {df.shape[1]} features')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Preparaci√≥n de Features (¬°Evitando Leakage!)\n",
                "\n",
                "‚ö†Ô∏è **IMPORTANTE**: NO usar `preliminary_credit_score` como feature"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Features PERMITIDAS (datos crudos, sin leakage)\n",
                "FEATURES = [\n",
                "    'age',                      # Demograf√≠a\n",
                "    'avg_balance',              # Balance\n",
                "    'last_balance',\n",
                "    'min_balance',\n",
                "    'max_balance',\n",
                "    'total_spend',              # Gasto\n",
                "    'avg_spend',\n",
                "    'max_spend',\n",
                "    'min_spend',\n",
                "    'std_spend',\n",
                "    'total_transactions',       # Actividad\n",
                "    'days_active',\n",
                "    'unique_transaction_days',\n",
                "    'transaction_frequency',\n",
                "    'spend_to_balance_ratio',   # Ratios\n",
                "    'spend_volatility',\n",
                "    'avg_daily_transactions',\n",
                "    'avg_daily_spend',\n",
                "]\n",
                "\n",
                "# Variable objetivo\n",
                "TARGET = 'high_risk_flag'\n",
                "\n",
                "print(f'üìä Features a usar: {len(FEATURES)}')\n",
                "print(f'üéØ Variable objetivo: {TARGET}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Verificar features disponibles\n",
                "available_features = [f for f in FEATURES if f in df.columns]\n",
                "missing_features = [f for f in FEATURES if f not in df.columns]\n",
                "\n",
                "print(f'‚úÖ Features disponibles: {len(available_features)}')\n",
                "if missing_features:\n",
                "    print(f'‚ö†Ô∏è Features no encontradas: {missing_features}')\n",
                "\n",
                "FEATURES = available_features"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Crear X e y\n",
                "X = df[FEATURES].copy()\n",
                "y = df[TARGET].copy()\n",
                "\n",
                "print(f'X shape: {X.shape}')\n",
                "print(f'y shape: {y.shape}')\n",
                "print(f'\\nüìä Distribuci√≥n del target:')\n",
                "print(y.value_counts(normalize=True).round(4) * 100)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Manejar valores nulos\n",
                "print('\\nüìä Nulos por columna antes de imputar:')\n",
                "null_counts = X.isnull().sum()\n",
                "print(null_counts[null_counts > 0])\n",
                "\n",
                "# Imputar nulos con la mediana\n",
                "X = X.fillna(X.median())\n",
                "\n",
                "print('\\n‚úÖ Nulos despu√©s de imputar:', X.isnull().sum().sum())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Divisi√≥n Train/Test"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Divisi√≥n estratificada (mantiene proporci√≥n de clases)\n",
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    X, y, \n",
                "    test_size=0.2, \n",
                "    random_state=42, \n",
                "    stratify=y\n",
                ")\n",
                "\n",
                "print(f'üìä Train: {X_train.shape[0]:,} samples ({X_train.shape[0]/len(X)*100:.0f}%)')\n",
                "print(f'üìä Test:  {X_test.shape[0]:,} samples ({X_test.shape[0]/len(X)*100:.0f}%)')\n",
                "\n",
                "print(f'\\nüìä Distribuci√≥n en Train:')\n",
                "print(y_train.value_counts(normalize=True).round(4) * 100)\n",
                "\n",
                "print(f'\\nüìä Distribuci√≥n en Test:')\n",
                "print(y_test.value_counts(normalize=True).round(4) * 100)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Escalar features para Logistic Regression\n",
                "scaler = StandardScaler()\n",
                "X_train_scaled = scaler.fit_transform(X_train)\n",
                "X_test_scaled = scaler.transform(X_test)\n",
                "\n",
                "print('‚úÖ Features escaladas')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Modelo 1: Logistic Regression (Baseline)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Entrenar Logistic Regression\n",
                "lr_model = LogisticRegression(\n",
                "    max_iter=1000,\n",
                "    random_state=42,\n",
                "    class_weight='balanced'\n",
                ")\n",
                "\n",
                "lr_model.fit(X_train_scaled, y_train)\n",
                "\n",
                "# Predicciones\n",
                "y_pred_lr = lr_model.predict(X_test_scaled)\n",
                "y_prob_lr = lr_model.predict_proba(X_test_scaled)[:, 1]\n",
                "\n",
                "# M√©tricas\n",
                "lr_auc = roc_auc_score(y_test, y_prob_lr)\n",
                "lr_gini = 2 * lr_auc - 1\n",
                "\n",
                "print('=' * 50)\n",
                "print('üìä LOGISTIC REGRESSION - Resultados')\n",
                "print('=' * 50)\n",
                "print(f'ROC-AUC: {lr_auc:.4f}')\n",
                "print(f'Gini:    {lr_gini:.4f}')\n",
                "print(f'\\n{classification_report(y_test, y_pred_lr, target_names=[\"Low Risk\", \"High Risk\"])}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Coeficientes (interpretabilidad)\n",
                "coef_df = pd.DataFrame({\n",
                "    'Feature': FEATURES,\n",
                "    'Coeficiente': lr_model.coef_[0]\n",
                "}).sort_values('Coeficiente', key=abs, ascending=False)\n",
                "\n",
                "print('üìä Features m√°s importantes (Logistic Regression):')\n",
                "print(coef_df.head(10).to_string(index=False))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Modelo 2: Random Forest"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Entrenar Random Forest\n",
                "rf_model = RandomForestClassifier(\n",
                "    n_estimators=100,\n",
                "    max_depth=10,\n",
                "    min_samples_split=10,\n",
                "    random_state=42,\n",
                "    class_weight='balanced',\n",
                "    n_jobs=-1\n",
                ")\n",
                "\n",
                "rf_model.fit(X_train, y_train)\n",
                "\n",
                "# Predicciones\n",
                "y_pred_rf = rf_model.predict(X_test)\n",
                "y_prob_rf = rf_model.predict_proba(X_test)[:, 1]\n",
                "\n",
                "# M√©tricas\n",
                "rf_auc = roc_auc_score(y_test, y_prob_rf)\n",
                "rf_gini = 2 * rf_auc - 1\n",
                "\n",
                "print('=' * 50)\n",
                "print('üìä RANDOM FOREST - Resultados')\n",
                "print('=' * 50)\n",
                "print(f'ROC-AUC: {rf_auc:.4f}')\n",
                "print(f'Gini:    {rf_gini:.4f}')\n",
                "print(f'\\n{classification_report(y_test, y_pred_rf, target_names=[\"Low Risk\", \"High Risk\"])}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Feature Importance\n",
                "importance_df = pd.DataFrame({\n",
                "    'Feature': FEATURES,\n",
                "    'Importance': rf_model.feature_importances_\n",
                "}).sort_values('Importance', ascending=False)\n",
                "\n",
                "# Visualizar\n",
                "plt.figure(figsize=(10, 8))\n",
                "plt.barh(importance_df['Feature'][::-1], importance_df['Importance'][::-1], color='steelblue')\n",
                "plt.xlabel('Importancia')\n",
                "plt.title('Feature Importance - Random Forest', fontsize=14, fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print('\\nüìä Top 10 Features (Random Forest):')\n",
                "print(importance_df.head(10).to_string(index=False))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Modelo 3: XGBoost"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calcular scale_pos_weight para manejar desbalanceo\n",
                "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
                "print(f'Scale pos weight: {scale_pos_weight:.2f}')\n",
                "\n",
                "# Entrenar XGBoost\n",
                "xgb_model = XGBClassifier(\n",
                "    n_estimators=100,\n",
                "    max_depth=6,\n",
                "    learning_rate=0.1,\n",
                "    scale_pos_weight=scale_pos_weight,\n",
                "    random_state=42,\n",
                "    eval_metric='auc',\n",
                "    use_label_encoder=False\n",
                ")\n",
                "\n",
                "xgb_model.fit(X_train, y_train)\n",
                "\n",
                "# Predicciones\n",
                "y_pred_xgb = xgb_model.predict(X_test)\n",
                "y_prob_xgb = xgb_model.predict_proba(X_test)[:, 1]\n",
                "\n",
                "# M√©tricas\n",
                "xgb_auc = roc_auc_score(y_test, y_prob_xgb)\n",
                "xgb_gini = 2 * xgb_auc - 1\n",
                "\n",
                "print('=' * 50)\n",
                "print('üìä XGBOOST - Resultados')\n",
                "print('=' * 50)\n",
                "print(f'ROC-AUC: {xgb_auc:.4f}')\n",
                "print(f'Gini:    {xgb_gini:.4f}')\n",
                "print(f'\\n{classification_report(y_test, y_pred_xgb, target_names=[\"Low Risk\", \"High Risk\"])}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. üéØ Modelo 4: Random Forest - SOLO COMPORTAMIENTO\n",
                "\n",
                "‚ö†Ô∏è **PRUEBA DE ROBUSTEZ**: ¬øEl modelo puede predecir riesgo SIN conocer los balances?\n",
                "\n",
                "**Variables EXCLUIDAS**:\n",
                "- `avg_balance`, `last_balance`, `min_balance`, `max_balance`\n",
                "- `spend_to_balance_ratio`\n",
                "\n",
                "**Variables INCLUIDAS** (solo comportamiento):\n",
                "- `age`, `avg_spend`, `total_spend`, `total_transactions`, `days_active`, etc."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Features SOLO DE COMPORTAMIENTO (sin balance)\n",
                "FEATURES_BEHAVIOR = [\n",
                "    'age',                      # Demograf√≠a\n",
                "    'total_spend',              # Gasto\n",
                "    'avg_spend',\n",
                "    'max_spend',\n",
                "    'min_spend',\n",
                "    'std_spend',\n",
                "    'total_transactions',       # Actividad\n",
                "    'days_active',\n",
                "    'unique_transaction_days',\n",
                "    'transaction_frequency',\n",
                "    'spend_volatility',\n",
                "    'avg_daily_transactions',\n",
                "    'avg_daily_spend',\n",
                "]\n",
                "\n",
                "# Variables EXCLUIDAS\n",
                "EXCLUDED_FEATURES = [\n",
                "    'avg_balance', 'last_balance', 'min_balance', 'max_balance',\n",
                "    'spend_to_balance_ratio'\n",
                "]\n",
                "\n",
                "print('‚úÖ Features de COMPORTAMIENTO (sin balance):')\n",
                "for f in FEATURES_BEHAVIOR:\n",
                "    print(f'   ‚Ä¢ {f}')\n",
                "\n",
                "print(f'\\n‚ùå Features EXCLUIDAS (tienen balance):')\n",
                "for f in EXCLUDED_FEATURES:\n",
                "    print(f'   ‚ö†Ô∏è {f}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Filtrar features disponibles\n",
                "FEATURES_BEHAVIOR = [f for f in FEATURES_BEHAVIOR if f in df.columns]\n",
                "\n",
                "# Crear X para comportamiento\n",
                "X_behavior = df[FEATURES_BEHAVIOR].copy()\n",
                "X_behavior = X_behavior.fillna(X_behavior.median())\n",
                "\n",
                "print(f'üìä Features de comportamiento: {len(FEATURES_BEHAVIOR)}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Divisi√≥n Train/Test para modelo de comportamiento\n",
                "X_train_beh, X_test_beh, y_train_beh, y_test_beh = train_test_split(\n",
                "    X_behavior, y, \n",
                "    test_size=0.2, \n",
                "    random_state=42, \n",
                "    stratify=y\n",
                ")\n",
                "\n",
                "print(f'üìä Train: {X_train_beh.shape[0]:,} samples')\n",
                "print(f'üìä Test:  {X_test_beh.shape[0]:,} samples')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Entrenar Random Forest - Solo Comportamiento\n",
                "rf_behavior = RandomForestClassifier(\n",
                "    n_estimators=100,\n",
                "    max_depth=10,\n",
                "    min_samples_split=10,\n",
                "    random_state=42,\n",
                "    class_weight='balanced',\n",
                "    n_jobs=-1\n",
                ")\n",
                "\n",
                "rf_behavior.fit(X_train_beh, y_train_beh)\n",
                "\n",
                "# Predicciones\n",
                "y_pred_beh = rf_behavior.predict(X_test_beh)\n",
                "y_prob_beh = rf_behavior.predict_proba(X_test_beh)[:, 1]\n",
                "\n",
                "# M√©tricas\n",
                "beh_auc = roc_auc_score(y_test_beh, y_prob_beh)\n",
                "beh_gini = 2 * beh_auc - 1\n",
                "\n",
                "print('=' * 60)\n",
                "print('üìä RANDOM FOREST - SOLO COMPORTAMIENTO (Sin Balance)')\n",
                "print('=' * 60)\n",
                "print(f'ROC-AUC: {beh_auc:.4f}')\n",
                "print(f'Gini:    {beh_gini:.4f}')\n",
                "print(f'\\n{classification_report(y_test_beh, y_pred_beh, target_names=[\"Low Risk\", \"High Risk\"])}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Feature Importance - Comportamiento\n",
                "importance_beh_df = pd.DataFrame({\n",
                "    'Feature': FEATURES_BEHAVIOR,\n",
                "    'Importance': rf_behavior.feature_importances_\n",
                "}).sort_values('Importance', ascending=False)\n",
                "\n",
                "# Visualizar\n",
                "plt.figure(figsize=(10, 6))\n",
                "plt.barh(importance_beh_df['Feature'][::-1], importance_beh_df['Importance'][::-1], color='coral')\n",
                "plt.xlabel('Importancia')\n",
                "plt.title('Feature Importance - Solo Comportamiento (Sin Balance)', fontsize=14, fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print('\\nüìä Features m√°s importantes (Solo Comportamiento):')\n",
                "print(importance_beh_df.to_string(index=False))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Comparaci√≥n: Con Balance vs Sin Balance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# KS\n",
                "def calculate_ks(y_true, y_prob):\n",
                "    fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
                "    return max(tpr - fpr)\n",
                "\n",
                "ks_lr = calculate_ks(y_test, y_prob_lr)\n",
                "ks_rf = calculate_ks(y_test, y_prob_rf)\n",
                "ks_xgb = calculate_ks(y_test, y_prob_xgb)\n",
                "ks_beh = calculate_ks(y_test_beh, y_prob_beh)\n",
                "\n",
                "# Tabla comparativa\n",
                "comparison = pd.DataFrame({\n",
                "    'Modelo': ['Logistic Regression', 'Random Forest', 'XGBoost', 'RF Solo Comportamiento'],\n",
                "    'ROC-AUC': [lr_auc, rf_auc, xgb_auc, beh_auc],\n",
                "    'Gini': [lr_gini, rf_gini, xgb_gini, beh_gini],\n",
                "    'KS': [ks_lr, ks_rf, ks_xgb, ks_beh],\n",
                "    'Usa Balance': ['S√≠', 'S√≠', 'S√≠', 'NO']\n",
                "}).round(4)\n",
                "\n",
                "print('=' * 70)\n",
                "print('üìä COMPARACI√ìN: CON BALANCE vs SIN BALANCE')\n",
                "print('=' * 70)\n",
                "print(comparison.to_string(index=False))\n",
                "print('=' * 70)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualizaci√≥n comparativa\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "models = ['LR', 'RF', 'XGB', 'RF\\n(Comportamiento)']\n",
                "colors = ['#3498db', '#2ecc71', '#e74c3c', '#f39c12']\n",
                "aucs = [lr_auc, rf_auc, xgb_auc, beh_auc]\n",
                "\n",
                "# ROC-AUC\n",
                "bars = axes[0].bar(models, aucs, color=colors)\n",
                "axes[0].set_title('ROC-AUC por Modelo', fontsize=14, fontweight='bold')\n",
                "axes[0].set_ylim(0, 1.1)\n",
                "axes[0].axhline(0.7, color='gray', linestyle='--', alpha=0.5, label='Umbral aceptable (0.7)')\n",
                "for i, v in enumerate(aucs):\n",
                "    axes[0].text(i, v + 0.02, f'{v:.4f}', ha='center', fontweight='bold')\n",
                "axes[0].legend()\n",
                "\n",
                "# Curvas ROC\n",
                "fpr_beh, tpr_beh, _ = roc_curve(y_test_beh, y_prob_beh)\n",
                "\n",
                "axes[1].plot(fpr_lr, tpr_lr, label=f'LR (AUC={lr_auc:.3f})', linewidth=2)\n",
                "axes[1].plot(fpr_rf, tpr_rf, label=f'RF (AUC={rf_auc:.3f})', linewidth=2)\n",
                "axes[1].plot(fpr_xgb, tpr_xgb, label=f'XGB (AUC={xgb_auc:.3f})', linewidth=2)\n",
                "axes[1].plot(fpr_beh, tpr_beh, label=f'RF Comportamiento (AUC={beh_auc:.3f})', linewidth=2, linestyle='--')\n",
                "axes[1].plot([0, 1], [0, 1], 'k--', alpha=0.5)\n",
                "axes[1].set_xlabel('False Positive Rate')\n",
                "axes[1].set_ylabel('True Positive Rate')\n",
                "axes[1].set_title('Curvas ROC', fontsize=14, fontweight='bold')\n",
                "axes[1].legend(loc='lower right')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Conclusiones"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print('=' * 70)\n",
                "print('üìä CONCLUSIONES - NeoScore Credit Scoring')\n",
                "print('=' * 70)\n",
                "\n",
                "# Interpretaci√≥n\n",
                "drop_in_auc = rf_auc - beh_auc\n",
                "pct_drop = (drop_in_auc / rf_auc) * 100\n",
                "\n",
                "print(f'''\n",
                "1. MODELOS CON BALANCE (RF Completo):\n",
                "   - ROC-AUC: {rf_auc:.4f}\n",
                "   - ‚ö†Ô∏è Puede estar \"haciendo trampa\" usando balance para predecir riesgo\n",
                "\n",
                "2. MODELO SOLO COMPORTAMIENTO (RF Sin Balance):\n",
                "   - ROC-AUC: {beh_auc:.4f}\n",
                "   - Ca√≠da en AUC: {drop_in_auc:.4f} ({pct_drop:.1f}%)\n",
                "   - Este es el RENDIMIENTO REAL del modelo sin \"trampa\"\n",
                "\n",
                "3. INTERPRETACI√ìN:\n",
                "''')\n",
                "\n",
                "if beh_auc >= 0.70:\n",
                "    print('   ‚úÖ El modelo de comportamiento tiene AUC >= 0.70')\n",
                "    print('   ‚úÖ PUEDE predecir riesgo sin conocer el balance')\n",
                "    print('   ‚úÖ El modelo es ROBUSTO y √∫til para producci√≥n')\n",
                "elif beh_auc >= 0.60:\n",
                "    print('   ‚ö†Ô∏è El modelo de comportamiento tiene AUC entre 0.60-0.70')\n",
                "    print('   ‚ö†Ô∏è Capacidad predictiva MODERADA sin balance')\n",
                "    print('   ‚ö†Ô∏è Considerar agregar m√°s features de comportamiento')\n",
                "else:\n",
                "    print('   ‚ùå El modelo de comportamiento tiene AUC < 0.60')\n",
                "    print('   ‚ùå El comportamiento SOLO no es suficiente para predecir riesgo')\n",
                "    print('   ‚ùå El modelo original depend√≠a demasiado del balance')\n",
                "\n",
                "print(f'''\n",
                "4. FEATURES M√ÅS IMPORTANTES (Sin Balance):\n",
                "''')\n",
                "print(importance_beh_df.head(5).to_string(index=False))\n",
                "\n",
                "print('\\n' + '=' * 70)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}