{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üè¶ NeoScore - Data Cleaning & Upload to BigQuery\n",
                "\n",
                "**Autor**: Luca Camus  \n",
                "**Fecha**: Enero 2026  \n",
                "**Objetivo**: Limpiar datos transaccionales y cargarlos a BigQuery"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Instalaci√≥n y Configuraci√≥n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Instalar dependencias\n",
                "!pip install google-cloud-bigquery pyarrow pandas-gbq --quiet"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Autenticaci√≥n con Google Cloud\n",
                "from google.colab import auth\n",
                "auth.authenticate_user()\n",
                "\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "from google.cloud import bigquery\n",
                "import re\n",
                "\n",
                "# Configuraci√≥n del proyecto\n",
                "PROJECT_ID = \"scoring-bancario\"\n",
                "DATASET_ID = \"analisis_bancario\"\n",
                "TABLE_ID = \"scoring_transacciones\"\n",
                "\n",
                "print(\"‚úÖ Dependencias instaladas y autenticaci√≥n completa\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Cargar Datos desde Google Drive"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Montar Google Drive para acceder al CSV\n",
                "from google.colab import drive\n",
                "drive.mount('/content/drive')\n",
                "\n",
                "# ============================================================\n",
                "# IMPORTANTE: Ajusta esta ruta seg√∫n donde tengas tu archivo\n",
                "# ============================================================\n",
                "CSV_PATH = '/content/drive/MyDrive/Finanzas/Proyectos/Scoring bancario/archive (2)/bank_transactions.csv'\n",
                "\n",
                "print('‚úÖ Google Drive montado correctamente')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cargar el CSV desde Google Drive\n",
                "df = pd.read_csv(CSV_PATH)\n",
                "print(f\"üìä Dataset cargado: {df.shape[0]:,} filas x {df.shape[1]} columnas\")\n",
                "print(f\"\\nüìã Columnas originales:\\n{df.columns.tolist()}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Vista previa de los datos\n",
                "df.head(10)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Informaci√≥n del dataset\n",
                "df.info()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Funci√≥n de Sanitizaci√≥n de Nombres de Columnas"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def sanitize_column_names(df):\n",
                "    \"\"\"\n",
                "    Convierte nombres de columnas a snake_case compatible con BigQuery.\n",
                "    - Elimina par√©ntesis y caracteres especiales\n",
                "    - Convierte espacios a guiones bajos\n",
                "    - Convierte a min√∫sculas\n",
                "    \"\"\"\n",
                "    new_columns = {}\n",
                "    for col in df.columns:\n",
                "        # Remover par√©ntesis y su contenido opcional\n",
                "        new_name = re.sub(r'\\s*\\([^)]*\\)', '', col)\n",
                "        # Reemplazar espacios por guiones bajos\n",
                "        new_name = new_name.replace(' ', '_')\n",
                "        # Convertir a min√∫sculas\n",
                "        new_name = new_name.lower()\n",
                "        # Remover caracteres especiales restantes\n",
                "        new_name = re.sub(r'[^a-z0-9_]', '', new_name)\n",
                "        # Remover guiones bajos dobles\n",
                "        new_name = re.sub(r'_+', '_', new_name)\n",
                "        # Remover guiones bajos al inicio/final\n",
                "        new_name = new_name.strip('_')\n",
                "        new_columns[col] = new_name\n",
                "    \n",
                "    df = df.rename(columns=new_columns)\n",
                "    return df\n",
                "\n",
                "# Aplicar sanitizaci√≥n\n",
                "df = sanitize_column_names(df)\n",
                "print(f\"\\n‚úÖ Columnas sanitizadas:\\n{df.columns.tolist()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Limpieza de Datos\n",
                "\n",
                "### Problemas identificados en el CSV:\n",
                "1. **Fechas zombi**: `1/1/1800` usado como placeholder para datos faltantes\n",
                "2. **String 'nan'**: Algunos valores aparecen como texto 'nan' en vez de nulo\n",
                "3. **G√©nero nulo**: Campos vac√≠os que debemos mantener sin sesgar\n",
                "4. **Balance vac√≠o**: Algunos registros sin balance\n",
                "5. **A√±os futuros**: Fechas como '94' se interpretan como 2094"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\nüîß Iniciando limpieza de datos...\")\n",
                "total_rows = len(df)\n",
                "\n",
                "# 4.1 Limpiar CustomerDOB - Reemplazar fechas zombi por None\n",
                "# Detectado: l√≠neas 18, 24, 30, 37, etc. tienen '1/1/1800'\n",
                "zombie_dates = ['1/1/1800', '01/01/1800', 'nan', 'NaN', 'NaT', '']\n",
                "df['customerdob'] = df['customerdob'].replace(zombie_dates, None)\n",
                "df['customerdob'] = df['customerdob'].replace('nan', None)\n",
                "\n",
                "# Convertir a datetime donde sea posible\n",
                "df['customerdob'] = pd.to_datetime(df['customerdob'], format='%d/%m/%y', errors='coerce')\n",
                "\n",
                "# Corregir a√±os interpretados incorrectamente (ej: 94 -> 2094 deber√≠a ser 1994)\n",
                "# Si la fecha es futura, restar 100 a√±os\n",
                "mask_future = df['customerdob'] > pd.Timestamp.now()\n",
                "df.loc[mask_future, 'customerdob'] = df.loc[mask_future, 'customerdob'] - pd.DateOffset(years=100)\n",
                "\n",
                "dob_nulls = df['customerdob'].isna().sum()\n",
                "dob_pct = (dob_nulls / total_rows) * 100\n",
                "print(f\"   - Fechas zombi limpiadas. Nulos en DOB: {dob_nulls:,} ({dob_pct:.2f}% del total) ‚úÖ Aceptable\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4.2 Limpiar TransactionDate\n",
                "df['transactiondate'] = pd.to_datetime(df['transactiondate'], format='%d/%m/%y', errors='coerce')\n",
                "txn_nulls = df['transactiondate'].isna().sum()\n",
                "txn_pct = (txn_nulls / total_rows) * 100\n",
                "print(f\"   - TransactionDate convertido. Nulos: {txn_nulls:,} ({txn_pct:.2f}%)\")\n",
                "\n",
                "# 4.3 Limpiar CustGender - Mantener nulos como est√°n para no sesgar\n",
                "gender_nulls = df['custgender'].isna().sum()\n",
                "gender_pct = (gender_nulls / total_rows) * 100\n",
                "print(f\"   - G√©nero con nulos: {gender_nulls:,} ({gender_pct:.2f}%)\")\n",
                "\n",
                "# 4.4 Asegurar tipos num√©ricos correctos\n",
                "df['custaccountbalance'] = pd.to_numeric(df['custaccountbalance'], errors='coerce')\n",
                "df['transactionamount'] = pd.to_numeric(df['transactionamount'], errors='coerce')\n",
                "\n",
                "balance_nulls = df['custaccountbalance'].isna().sum()\n",
                "balance_pct = (balance_nulls / total_rows) * 100\n",
                "amount_nulls = df['transactionamount'].isna().sum()\n",
                "amount_pct = (amount_nulls / total_rows) * 100\n",
                "\n",
                "print(f\"   - Balance nulos: {balance_nulls:,} ({balance_pct:.2f}%)\")\n",
                "print(f\"   - Amount nulos: {amount_nulls:,} ({amount_pct:.2f}%)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4.5 Resumen de limpieza\n",
                "print(\"\\nüìä Resumen post-limpieza:\")\n",
                "print(df.info())\n",
                "print(f\"\\nüìà Estad√≠sticas descriptivas:\")\n",
                "df.describe()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Subir a BigQuery"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n‚òÅÔ∏è Subiendo a BigQuery...\")\n",
                "\n",
                "# Crear cliente de BigQuery\n",
                "client = bigquery.Client(project=PROJECT_ID)\n",
                "\n",
                "# Configurar el esquema expl√≠citamente para evitar problemas de tipos\n",
                "schema = [\n",
                "    bigquery.SchemaField(\"transactionid\", \"STRING\"),\n",
                "    bigquery.SchemaField(\"customerid\", \"STRING\"),\n",
                "    bigquery.SchemaField(\"customerdob\", \"DATE\"),\n",
                "    bigquery.SchemaField(\"custgender\", \"STRING\"),\n",
                "    bigquery.SchemaField(\"custlocation\", \"STRING\"),\n",
                "    bigquery.SchemaField(\"custaccountbalance\", \"FLOAT64\"),\n",
                "    bigquery.SchemaField(\"transactiondate\", \"DATE\"),\n",
                "    bigquery.SchemaField(\"transactiontime\", \"INT64\"),\n",
                "    bigquery.SchemaField(\"transactionamount\", \"FLOAT64\"),\n",
                "]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Configurar el job\n",
                "table_ref = f\"{PROJECT_ID}.{DATASET_ID}.{TABLE_ID}\"\n",
                "job_config = bigquery.LoadJobConfig(\n",
                "    schema=schema,\n",
                "    write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE,  # Sobreescribir\n",
                ")\n",
                "\n",
                "# Subir DataFrame\n",
                "job = client.load_table_from_dataframe(\n",
                "    df, \n",
                "    table_ref, \n",
                "    job_config=job_config\n",
                ")\n",
                "\n",
                "# Esperar a que termine\n",
                "job.result()\n",
                "\n",
                "# Verificar\n",
                "table = client.get_table(table_ref)\n",
                "print(f\"\\n‚úÖ Tabla creada exitosamente en BigQuery!\")\n",
                "print(f\"   üìç Ubicaci√≥n: {table_ref}\")\n",
                "print(f\"   üìä Filas cargadas: {table.num_rows:,}\")\n",
                "print(f\"   üíæ Tama√±o: {table.num_bytes / 1e6:.2f} MB\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Verificaci√≥n R√°pida"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "query = f\"\"\"\n",
                "SELECT \n",
                "    COUNT(*) as total_rows,\n",
                "    COUNT(DISTINCT customerid) as unique_customers,\n",
                "    MIN(transactiondate) as first_date,\n",
                "    MAX(transactiondate) as last_date,\n",
                "    AVG(transactionamount) as avg_amount\n",
                "FROM `{table_ref}`\n",
                "\"\"\"\n",
                "\n",
                "result = client.query(query).to_dataframe()\n",
                "print(\"\\nüìã Verificaci√≥n de datos en BigQuery:\")\n",
                "result"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\nüéâ ¬°Proceso completado exitosamente!\")\n",
                "print(\"\\nPr√≥ximos pasos:\")\n",
                "print(\"1. Ejecuta el SQL '02_customer_features.sql' en BigQuery\")\n",
                "print(\"2. Contin√∫a con el notebook de EDA\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}